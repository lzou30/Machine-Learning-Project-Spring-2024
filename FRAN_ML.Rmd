---
title: "Fran ML project code"
author: "Franciscb7
date: "2024-03-30"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Load packages

pacman::p_load(tidyverse, ggplot2, scales, glmnet, pls, randomForest, rpart, DescTools, readxl)

# Set custom theme
MK_theme <-   theme(text = element_text(family = "Times New Roman"),
                    panel.background = element_blank(),
                    axis.text.x.bottom = element_text(size = 12),
                    axis.text.y.left = element_text(size = 12),
                    axis.title.x.bottom = element_text(size = 16),
                    axis.title.y.left = element_text(size = 16),
                    title = element_text(size = 16, face = "bold"),
                    panel.border = element_rect(color = "black", linewidth = 0.3, fill = "transparent"),
                    panel.grid = element_line(color = "black", linewidth = 0.1),
                    legend.position = "none")
```

## 1. Go to Blackboard and download the files. Starting with the CFPB complaint data, please load the data into R and clean the data set. Please note, each team has a different random sample. 
# a. I am providing the code for the dependent variable “relief” from the company response variable. Please note, you will need to drop the company response variable before you do the modeling as this will perfectly predict the DV. 
# b. Your group needs to make decisions on how to treat the rest of this variable. In your write up, defend your answer. 
# i. How should “In progress” be coded? 
# ii.	Should the other conditions be coded into dummy variables? 
# c. All of the CFPB data documentation is located at https://cfpb.github.io/api/ccdb/fields.html . 
# i. While not required, it would be in your best interest to recode some of these variables to have shorter values in the name. 

```{r, echo = TRUE}
# Bring in data 
group1 <- read_csv("/Users/franciscuadros/Downloads/group1.csv")
colnames(group1)
group1 <- group1[,-1]

add_char <- function(x, pos, insert) {      
  gsub(paste0("^(.{", pos, "})(.*)$"),
       paste0("\\1", insert, "\\2"),
       x)
}

group1$ZIP.code <- ifelse(nchar(group1$ZIP.code) == 4, add_char(x = group1$ZIP.code,
                                                                     pos = 0, 
                                                                     insert = "0"), group1$ZIP.code)

which(nchar(group1$ZIP.code) == 4) # no four-digit zip codes
group1.1 <- group1 %>%
  filter(State != "AE" & State != "AP") # Remove non-state observations

# Load in zip_fips
zip_fips <- read_csv("/Users/franciscuadros/Downloads/zip_fips.csv")
colnames(zip_fips)
zip_fips <- zip_fips[,-1]
str(zip_fips$ZIP)
table(zip_fips$STATE)

# Filter non-US states
zip_fips_states <- zip_fips %>%
  filter(STATE != "PR" & STATE != "GU" & STATE != "DC" & STATE != "VI")

# Add leading zero
add_char <- function(x, pos, insert) {      
  gsub(paste0("^(.{", pos, "})(.*)$"),
       paste0("\\1", insert, "\\2"),
       x)
}

zip_fips_states$ZIP <- ifelse(nchar(zip_fips_states$ZIP) == 4, add_char(x = zip_fips_states$ZIP,
                                                                     pos = 0, 
                                                                     insert = "0"), zip_fips_states$ZIP)

# Merge datasets to find odd zip codes
group1.2 <- merge(group1.1, zip_fips_states, 
                       by.x = c("ZIP.code", "State"),
                       by.y = c("ZIP", "STATE"), all.x = TRUE)

group1.2$missing_zip <- as.factor(is.na(group1.2$STCOUNTYFP))
group1.2 <- group1.2[,-15] # Drop company response to consumer

# group1_merged$missing <- as.factor(complete.cases(group1_merged))
# group1_merged <- group1_merged[,-c(20:21)]
# group1_merged$ZIP.code <- as.factor(group1_merged$ZIP.code)
# noy <- is.na(group1_merged$relief)
# group1_merged <- group1_merged[which(noy == 0),]


```

## 2. Your first task is to clean the zip code variable. Many of the zip codes are missing, incomplete, or missing the leading zero. Your group must pick a missing data method to fix this data!
# a.	For the dependent variable (relief) and 3 other variables of your choosing, do a simple statistical comparison (2 sample proportions or t-test, Chi-Square,…) to check for differences between the subgroups that are missing zip code and those that provided the information. 
# i. Suggestion: You will want to create a dummy variable to indicate if the variable is missing for the rest of the analysis. Using the aggregate() function in r, this should be an easy task. 


```{r}
# Submitted.via
table(group1.2$Submitted.via, group1.2$missing_zip)
group1.3 <- group1.2 %>%
  mutate(Submitted.via = case_when(Submitted.via == "Web Referral" ~ "Referral",
            Submitted.via == "Web" ~ "Web", 
            Submitted.via == "Referral" ~ "Referral",
            Submitted.via == "Postal mail" ~ "Postal mail",
            Submitted.via == "Phone" ~ "Phone",
            Submitted.via == "Fax" ~ "Fax")) # Recode Web Referral to Referral
table(group1.3$Submitted.via, group1.3$missing_zip) # Meets assumptions now :) 
chisq.test(group1.3$Submitted.via, group1.3$missing_zip) # p-value significant

# Tags
table(group1.3$Tags, group1.3$missing_zip)
chisq.test(group1.3$Tags, group1.3$missing_zip) # Does not meet assumptions, no difference between the two groups 
fisher.test(group1.3$Tags, group1.3$missing_zip) # p-val 0.3182 

# Relief
table(group1.3$relief, group1.3$missing_zip)
chisq.test(group1.3$relief, group1.3$missing_zip) # p-value = 1

# Timely.response
table(group1.3$Timely.response., group1.3$missing_zip)
chisq.test(group1.3$Timely.response., group1.3$missing_zip) # p-value *almost* significant

```

# b. Please note, you have the state in all cases. You must fix the fill this field with a zip code that is a plausible value (the corrected/imputed zip code must be from the State listed). 
# i. You can drop any non-state in the analysis. (“DC”, “UNITED STATES MINOR OUTLYING ISLANDS”, “AA” (Armed Forces), …) 
# c. Any imputation method is acceptable as long as you defend your choice. You can use mean/mode replacement, nearest neighbor, regression based models, …
```{r}
# Use mode to impute zip code
group1.4 <- group1.3 %>%
  group_by(State) %>%
  mutate(imp_zip = ifelse(missing_zip == TRUE, Mode(ZIP.code),  ZIP.code))

```

# d.	Please indicate any limitations or biases your imputation has on the analysis? 
# i. If I replace all values with the state capital zip code, how would that impact my analysis?
group1.5 <- group1.4[,-c(19:20)] # remove COUNTYNAME & STCOUNTYFP
group1.6 <- merge(group1.5, zip_fips_states, by.x = c("imp_zip", "State"), by.y = c("ZIP", "STATE"))

add_char <- function(x, pos, insert) {      
  gsub(paste0("^(.{", pos, "})(.*)$"),
       paste0("\\1", insert, "\\2"),
       x)
}

group1.6$STCOUNTYFP <- ifelse(nchar(group1.6$STCOUNTYFP) == 4, add_char(x = group1.6$STCOUNTYFP,
                                                                     pos = 0, 
                                                                     insert = "0"), group1.6$STCOUNTYFP)
                                                                     
county_debt <- read_excel("/Users/franciscuadros/Downloads/dia_lbls_all_overall_county_2022_02_14Sep2023.xlsx")
names(county_debt)[names(county_debt) == "County FIPS" ] <- "fips"
group1.6$fips <- ifelse(nchar(group1.6$STCOUNTYFP) == 4, add_char(x = group1.6$STCOUNTYFP,
                                                                     pos = 0, 
                                                                     insert = "0"), group1.6$STCOUNTYFP)
group1.7 <- merge(group1.6, county_debt, by == "fips", all.x = TRUE)

